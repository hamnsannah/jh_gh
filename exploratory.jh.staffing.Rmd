---
title: "Staffing Analysis - Sample Store"
author: "Allocate Analytics"
date: "February 9, 2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(ggplot2)
library(sugrrants)
library(lubridate)
library(fpp2)
#library(prophet)

#data.clean <- read.csv("data/mutated.data1417.csv", stringsAsFactors = FALSE)

#####
import.jh.sql.connect <- function(db.name.in.sql.server){
  library(odbc)
  library(DBI)
  
  con <- DBI::dbConnect(odbc::odbc(),
                        Driver = "SQL Server",
                        Server = "LAPTOP-JHRVTF04\\SQLEXPRESS",
                        Database = db.name.in.sql.server,
                        Trusted_Connection = "True")
  con
}

import.jh.detailed.sales <- function(){
  joined.df <- DBI::dbGetQuery(con,'
                                SELECT TransactionEntry.ItemID, TransactionEntry.Price, 
                                 TransactionEntry.TransactionTime, TransactionEntry.Quantity, 
                                  TransactionEntry.TransactionNumber, Item.Description, 
                                 Department.Name AS "Department", Category.Name AS "Category", 
                                 SupplierName AS "Supplier", Cashier.Name AS "CashierName", 
                                 Register.Number AS "Register", Register.Description AS "RegLocation"

                                 FROM TransactionEntry
                                 
                                 JOIN Item ON TransactionEntry.ItemID = Item.ID
                                 JOIN Department ON Item.DepartmentID = Department.ID
                                 JOIN Category ON Item.CategoryID = Category.ID
                                 JOIN Supplier ON Item.SupplierID = Supplier.ID
                                 JOIN [Transaction] ON TransactionEntry.TransactionNumber = [Transaction].TransactionNumber
                                 JOIN Batch ON [Transaction].BatchNumber = Batch.BatchNumber
                                 JOIN Register ON Batch.RegisterID = Register.ID
                                 JOIN Cashier ON [Transaction].CashierID = Cashier.ID')
  joined.df
  }

clean.jh.detailed.sales <- function(sql.df){
  library(dplyr)
  library(lubridate)
    
    sql.df <- sql.df %>%
      rename(Sold.Price = Price, Cashier = CashierName, Date.Sold = TransactionTime,
             Qty.Sold = Quantity, Transaction = TransactionNumber) %>%
      mutate(Total.Sales = Qty.Sold*Sold.Price) %>%
      select(Department, Category, Supplier, ItemID, Description, Qty.Sold, Sold.Price, 
             Total.Sales, Transaction, Date.Sold, Register, Cashier)
    
    sql.df$Date.Sold <- ymd_hms(sql.df$Date.Sold)
    sql.df$Year <- year(sql.df$Date.Sold)
    sql.df$Month <- month(sql.df$Date.Sold)
    sql.df$Department <- trimws(sql.df$Department)
    sql.df$Category <- trimws(sql.df$Category)
    sql.df$Supplier <- trimws(sql.df$Supplier)
    sql.df$Item <- trimws(sql.df$Item)
    #print(head(sql.df))
    sql.df$Dept.By.Year <- paste(sql.df$Department, sql.df$Year)
    sql.df$Categ.By.Year <- paste(sql.df$Category, sql.df$Year)
    sql.df
}
if(file.exists(paste0("data/sales.data.cache", Sys.Date(), ".csv"))){
  data.clean <- read.csv(paste0("data/sales.data.cache", Sys.Date(), ".csv"), stringsAsFactor = FALSE)
} else {
con <- import.jh.sql.connect("Sam's Store")

new.df <- import.jh.detailed.sales() # uses con but not as argument

data.clean <- clean.jh.detailed.sales(new.df)

write.csv(data.clean, paste0("data/sales.data.cache", Sys.Date(), ".csv"), row.names = FALSE)
}

#####
#data.clean <- filter(data.clean, Register != "9")

data.wide <- data.clean
data.wide$Date.Sold <- ymd_hms(data.wide$Date.Sold)
data.wide$Date.Sold.Round <- floor_date(data.wide$Date.Sold, unit = "hour")
data.wide$Date.Sold <- as_date(data.wide$Date.Sold)
data.wide$Date.Sold.Round <- as_datetime(data.wide$Date.Sold.Round)

data17 <- filter(data.wide, Year == 2017)
#print(str(data17))
print(head(data17))

data17.agg <- aggregate(Total.Sales ~ Date.Sold.Round + Date.Sold, data17, sum)
data17.agg <- data17.agg %>%
  mutate("Hour" = as.integer(hour(Date.Sold.Round))) %>%
  frame_calendar(x = Hour, y = Total.Sales, date = Date.Sold, calendar = "monthly")
data17.plot <- data17.agg %>%
  ggplot(aes(x = .Hour, y = .Total.Sales, group = Date.Sold)) + geom_line()

```

### Staffing Based on Sales in Recent Months
######Note: The calculations for the yellow dots are placeholders.  More information is needed before creating staffing projections from sales.  However, the blue areas and red line are based on real data.  The blue areas represent sales for that hour 50% of the time, 75%, and 95%.  The red is the mean or average. 

```{r off.peak.minimum, echo=FALSE, warning=FALSE, message=FALSE}

data2years.wide <- filter(data.wide, Year %in% c(2017, 2018))

#data2years$Date.Sold <- as_date(data2years$Date.Sold)

data2years.wide <- data2years.wide %>%
  mutate("Hour" = hour(Date.Sold.Round)) %>%
  mutate("Weekday" = wday((Date.Sold.Round)))
    
# filter for recent months since July ##
df1 <- data2years.wide %>%
  filter(Date.Sold >= "2018-07-01", Date.Sold <= "2018-12-17")
#df2 <- data2years.wide %>%
#  filter(Date.Sold >= "2016-02-01", Date.Sold <= "2016-04-07", Weekday %in% c(1, 2, 3, 4, 5, 7))

#print(head(df2))
#print(tail(df2))

df.all <- df1
#df.all <- rbind(df1, df2)

# need to go back to original script and add additional start dates with defaults like 0 for min and 100000 for max
staffing.day.plot.2 <- function(df, nickname.of.time.range){
  
  library(lubridate)
  library(dplyr)
  library(ggplot2)
  
  df.agg <- aggregate(Total.Sales ~ Date.Sold.Round + Hour + Weekday, df.all, sum)
  conf.df <- data.frame()
  
  for(i in 9:23){
    print(i)
    i.hour.vec <- df.agg %>%
      filter(Hour == i) %>%
      select(Total.Sales)
    #i.hour.vec <- as.double(i.hour.vec)
    print(head(i.hour.vec))
    #i.estimate.95 <- t.test(i.hour.vec, conf.level = 0.95)$estimate
    #i.conf.int.95 <- t.test(i.hour.vec, conf.level = 0.95)$conf.int
    #i.conf.int.75 <- t.test(i.hour.vec, conf.level = 0.75)$conf.int
    #i.conf.int.50 <- t.test(i.hour.vec, conf.level = 0.50)$conf.int
    #three.conf.int <- c(i, i.estimate.95, i.conf.int.95, i.conf.int.75, i.conf.int.50)
    quantiles <- quantile(as.numeric(unlist(i.hour.vec)), probs = c(.5, .025, .975, .125, .875, .25, .75))
    print(class(quantiles))
    
    quantiles.hour <- c(i, quantiles)
    print(class(quantiles.hour))
    conf.df <- rbind(conf.df, quantiles.hour)
    
    #i.estimate.95 <- quantie(i.hour.vec, .5)
    #i.conf.int.95.high <- 
    #quantiles.hour <- c(i, quantile(i.hour.vec, c(.5, .025, .975, .125, .875, .25, .75)))
  }
    colnames(conf.df) <- c("hour", "estimate", "low95", "high95", "low75", "high75", "low50", "high50")
    
    day.plot <- ggplot(data = conf.df, aes(x=hour)) +
      geom_ribbon(aes(ymin=low95, ymax=high95), fill="#0571b0", alpha = .75)+
      geom_ribbon(aes(ymin=low75, ymax=high75), fill="#92c5de", alpha = .75)+
      geom_ribbon(aes(ymin=low50, ymax=high50), fill="#d1e5f0", alpha = .75)+
      geom_ribbon(aes(ymin=estimate-20, ymax=estimate+20), fill="#ef8a62")
    print(day.plot)
}

#staffing.day.plot.2(df.all)


### function with staffing plot with yellow dots
staffing.day.plot.dots <- function(df, nickname.of.time.range){
  
  library(lubridate)
  library(dplyr)
  library(ggplot2)
  
  df.agg <- aggregate(Total.Sales ~ Date.Sold.Round + Hour + Weekday, df.all, sum)
  conf.df <- data.frame()
  
  for(i in 9:23){
    #print(i)
    i.hour.vec <- df.agg %>%
      filter(Hour == i) %>%
      select(Total.Sales)
    #i.hour.vec <- as.double(i.hour.vec)
    #print(head(i.hour.vec))
    #i.estimate.95 <- t.test(i.hour.vec, conf.level = 0.95)$estimate
    #i.conf.int.95 <- t.test(i.hour.vec, conf.level = 0.95)$conf.int
    #i.conf.int.75 <- t.test(i.hour.vec, conf.level = 0.75)$conf.int
    #i.conf.int.50 <- t.test(i.hour.vec, conf.level = 0.50)$conf.int
    #three.conf.int <- c(i, i.estimate.95, i.conf.int.95, i.conf.int.75, i.conf.int.50)
    quantiles <- quantile(as.numeric(unlist(i.hour.vec)), probs = c(.5, .025, .975, .125, .875, .25, .75))
    #print(class(quantiles))
    
    quantiles.hour <- c(i, quantiles)
    #print(class(quantiles.hour))
    conf.df <- rbind(conf.df, quantiles.hour)
    
    #i.estimate.95 <- quantie(i.hour.vec, .5)
    #i.conf.int.95.high <- 
    #quantiles.hour <- c(i, quantile(i.hour.vec, c(.5, .025, .975, .125, .875, .25, .75)))
  }
  colnames(conf.df) <- c("hour", "estimate", "low95", "high95", "low75", "high75", "low50", "high50")
  
  # add column corresponding to # of staff needed based on $400 -> 2, $600 -> 3, etc
  conf.df$staff.estimate <- (round(conf.df$high50/100)) ###### should be /200 for Whale's Tale
  
  lbls = paste0(as.character(c(seq(9, 12, 1), seq(1, 11, 1))), c(rep("am", 3), rep("pm", 12)))
  brks <- seq(9,23, 1)
  
  lbls.y = paste0("$", seq(0, 2000, 200))
  brks.y = seq(0, 2000, 200)
  brks.y2 = seq(0,8,1)
  
  ########
  #####change all these 100s to 200s if doing Whale's Tale, really need a way to isolate this equation in order to make changes easily
  ########
  
  day.plot <- ggplot(data = conf.df, aes(x=hour)) +
    geom_ribbon(aes(ymin=low95, ymax=high95), fill="#0571b0", alpha = .75)+
    geom_ribbon(aes(ymin=low75, ymax=high75), fill="#92c5de", alpha = .75)+
    geom_ribbon(aes(ymin=low50, ymax=high50), fill="#d1e5f0", alpha = .75)+
    geom_ribbon(aes(ymin=estimate-5, ymax=estimate+5), fill="#ef8a62") +
    geom_point(aes(y=staff.estimate*100), color="#FFFF33", size = 10) +
    geom_text(aes(y = staff.estimate*100, label = staff.estimate), color = "black", size = 5, fontface = "bold")
  day.plot <- day.plot + scale_x_continuous(labels = lbls, breaks = brks) + 
    scale_y_continuous(sec.axis = sec_axis(~./100, name = "Estimate of Hourly Staff Need", breaks = brks.y2), labels = lbls.y, breaks = brks.y, name = "Range of Hourly Sales") + theme_dark() #+ ylim(0,2000)
  #print(head(conf.df, 15))
  print(day.plot)
}

```

```{r peak.6.days, echo=FALSE, warning=FALSE, message=FALSE}

# filter for off.peak.minimum ##
#df1 <- data2years.wide %>%
#  filter(Date.Sold >= "2016-06-25", Date.Sold <= "2016-09-03", Weekday %in% c(1, 2, 3, 4, 5, 6))
#df2 <- data2years.wide %>%
#  filter(Date.Sold >= "2017-06-25", Date.Sold <= "2017-09-03", Weekday %in% c(1, 2, 3, 4, 5, 6))

#print(head(df2))
#print(tail(df2))

df.all <- df1
#df.all <- rbind(df1, df2)
staffing.day.plot.dots(df.all)

```
Notes:

* This chart is meant to answer the question how many staff are needed at the different points of the day.  The main assumption here is that more sales mean more customers present, which requires more staff to support them.

* The red area shows the average sales level for each hour for every sales day from July 1, 2018 to Dec 17, 2018.

* The blue areas show more information about the range of possibility....

\newpage
# Appendix: 
##Additional graphs used to determine how to group days together, determine seasonality, and delineate beginning and end of data set

## 2018 Calendar Plot

```{r, calendar.18.plot, echo=FALSE}
data18 <- filter(data.wide, Year == 2018)
#print(str(data17))
#print(head(data17))

data18.agg <- aggregate(Total.Sales ~ Date.Sold.Round + Date.Sold, data18, sum)
data18.agg <- data18.agg %>%
  mutate("Hour" = as.integer(hour(Date.Sold.Round))) %>%
  frame_calendar(x = Hour, y = Total.Sales, date = Date.Sold, calendar = "monthly")
data18.plot <- data18.agg %>%
  ggplot(aes(x = .Hour, y = .Total.Sales, group = Date.Sold)) + geom_line()
prettify(data18.plot)
```

\newpage
## 2017 Calendar Plot

```{r calendar.17.plot, echo=FALSE, warning=FALSE, message=FALSE}
#print(unique(data.clean$Register))
prettify(data17.plot)
```

\newpage
## 2016 Calendar Plot

```{r calendar.16.plot, echo=FALSE, warning=FALSE, message=FALSE}
data16 <- filter(data.wide, Year == 2016)

data16.agg <- aggregate(Total.Sales ~ Date.Sold.Round + Date.Sold, data16, sum)
data16.agg <- data16.agg %>%
  mutate("Hour" = as.integer(hour(Date.Sold.Round))) %>%
  frame_calendar(x = Hour, y = Total.Sales, date = Date.Sold, calendar = "monthly")
data16.plot <- data16.agg %>%
  ggplot(aes(x = .Hour, y = .Total.Sales, group = Date.Sold)) + geom_line()
prettify(data16.plot)

```

\newpage
### Evaluating Seasonality and Trend: Monthly Data

```{r time_series, echo = FALSE, warning=FALSE, message=FALSE}

exploratory.jh.time.series <- function(clean.df, freq = 365){
  require(lubridate)
  require(dplyr)
  clean.df <- arrange(clean.df, Date.Sold)
  clean.df$Day <- date(clean.df$Date.Sold) # df should have been arranged in cleaning step
  start.year <- year(clean.df$Day)[1]
  if(freq == 365){
    start.day <- date(head(clean.df$Day,1)) - floor_date(head(clean.df$Day,1), unit = "year")+1 # subtracts earliest day from first day of year plus one
    sales.agg <- aggregate(Total.Sales ~ Day, clean.df, sum)
    all.dates <- seq.Date(from = as.Date(min(sales.agg$Day, na.rm = TRUE)), to = as.Date(max(sales.agg$Day, na.rm = TRUE)),by = 1)
    sales.agg.all <- left_join(data.frame(Day = all.dates), sales.agg)
    sales.ts <- ts(sales.agg.all$Total.Sales, start = c(start.year, start.day), frequency = 365)
  }
  if(freq == 12){
    start.month <- month(head(clean.df$Month,1))
    sales.agg <- aggregate(Total.Sales ~ Month + Year, clean.df, sum)
    #print(head(sales.agg, 25))
    sales.agg.all <- left_join(sales.agg, data.frame(Month = 1:12))
    sales.ts <- ts(sales.agg.all$Total.Sales, start = c(start.year, start.month), frequency = 12)
  }
  sales.ts[is.na(sales.ts)] <- 0
  
  sales.ts
}

sales.ts <- exploratory.jh.time.series(data.clean, freq = 12)
autoplot(sales.ts)
sales.stl <- stl(sales.ts, s.window = 5)
autoplot(sales.stl)
```

\newpage
### Evaluating Seasonality and Trend: Daily Data

```{r time_series_daily, echo=FALSE, warning=FALSE, message=FALSE}
sales.ts <- exploratory.jh.time.series(data.clean)
autoplot(sales.ts)
sales.stl <- stl(sales.ts, s.window = 5)
autoplot(sales.stl)
```